{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db07f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ System Prompt 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# System Prompt 정의 (2025 모범 사례: 명확하고 구체적인 지시사항)\n",
    "SYSTEM_PROMPT = \"\"\"당신은 박사급 지식을 가진 전문적인 에이전트입니다. 사용자의 질문에 대해 논문 제출자 및 Peer 리뷰어급으로 상세하고 정확하게 답변해 주세요.\n",
    "\n",
    "당신의 답변은 다음 기준을 충족해야 합니다:\n",
    "1. 정확성: 답변은 사실에 기반해야 하며, 논문의 출처를 인용해야 합니다. \n",
    "2. 주제: 답변은 질문과 관련된 주제에 집중해야 합니다. 본 연구원은 KLSBench, 즉 한국의 한문 데이터베이스를 바탕으로 저자원 언어 처리에 필요한 벤치마크를 구축하는 연구를 수행하고 있습니다.\n",
    "\n",
    "도구 사용 가이드:\n",
    "- get_source: Arxiv에서 학술 논문을 검색할 때 사용합니다. 검색어는 구체적이고 관련성 높은 키워드를 사용하세요.\n",
    "\"\"\"\n",
    "\n",
    "print(\"✓ System Prompt 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tn141csv5vr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OPENAI_API_KEY 로드 완료\n",
      "✓ ANTHROPIC_API_KEY 로드 완료\n",
      "✓ PERPLEXITY_API_KEY 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# 환경 변수 로드 (2025 모범 사례: 보안을 위한 환경 변수 관리)\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 로드 확인 (보안상 실제 키 값은 표시하지 않음)\n",
    "api_keys = {\n",
    "    \"OPENAI_API_KEY\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"ANTHROPIC_API_KEY\": os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "    \"PERPLEXITY_API_KEY\": os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "}\n",
    "\n",
    "for key_name, key_value in api_keys.items():\n",
    "    if key_value:\n",
    "        print(f\"✓ {key_name} 로드 완료\")\n",
    "    else:\n",
    "        print(f\"✗ {key_name}를 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ecb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tools 정의 완료 (arxiv 네이티브 라이브러리 사용)\n"
     ]
    }
   ],
   "source": [
    "# Tools 정의 (2025 모범 사례: @tool 데코레이터 + 네이티브 arxiv 라이브러리)\n",
    "from langchain.tools import tool\n",
    "import arxiv\n",
    "\n",
    "@tool\n",
    "def get_source(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Arxiv에서 학술 논문을 검색합니다.\n",
    "    \n",
    "    이 도구는 다음과 같은 경우에 사용하세요:\n",
    "    - 특정 주제에 대한 최신 연구 논문을 찾을 때\n",
    "    - 저자원 언어 처리, 벤치마크, NLP 관련 연구를 검색할 때\n",
    "    - 학술적 근거가 필요한 답변을 작성할 때\n",
    "    \n",
    "    Args:\n",
    "        query (str): 검색할 키워드나 주제 (영어로 입력하는 것이 좋습니다)\n",
    "        \n",
    "    Returns:\n",
    "        str: 상위 5개 논문의 제목, 저자, 요약 정보\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # arxiv 네이티브 라이브러리 사용 (2025 권장)\n",
    "        client = arxiv.Client(\n",
    "            page_size=10,\n",
    "            delay_seconds=3,  # arXiv API 규정 준수\n",
    "            num_retries=3\n",
    "        )\n",
    "        \n",
    "        search = arxiv.Search(\n",
    "            query=query,\n",
    "            max_results=5,\n",
    "            sort_by=arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "        \n",
    "        results = []\n",
    "        for result in client.results(search):\n",
    "            paper_info = f\"\"\"\n",
    "제목: {result.title}\n",
    "저자: {', '.join([author.name for author in result.authors])}\n",
    "게시일: {result.published.strftime('%Y-%m-%d')}\n",
    "요약: {result.summary[:500]}...\n",
    "링크: {result.entry_id}\n",
    "---\n",
    "\"\"\"\n",
    "            results.append(paper_info)\n",
    "        \n",
    "        if results:\n",
    "            return \"\\n\".join(results)\n",
    "        else:\n",
    "            return \"검색 결과가 없습니다. 다른 키워드로 시도해보세요.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"논문 검색 중 오류 발생: {str(e)}\\n쿼리를 다시 확인하거나 네트워크 연결을 확인해주세요.\"\n",
    "\n",
    "print(\"✓ Tools 정의 완료 (arxiv 네이티브 라이브러리 사용)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yg1bv3fqij",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LLM 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# LLM 초기화 (2025 모범 사례: init_chat_model 사용)\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# init_chat_model: 모든 모델을 한 줄로 초기화하는 통합 인터페이스\n",
    "# 장점: \n",
    "# - 자동 provider 추론 (gpt-4 → openai, claude → anthropic)\n",
    "# - 런타임에 모델 교체 가능\n",
    "# - 통일된 API로 여러 provider 지원\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"gpt-4o\",           # 또는 \"gpt-4\", \"claude-3-opus-20240229\", \"gemini-2.5-pro\"\n",
    "    model_provider=\"openai\",  # provider는 자동 추론되지만 명시적으로 지정 가능\n",
    "    temperature=0.7,          # 창의성 조절 (0.0=결정적, 1.0=창의적)\n",
    "    timeout=30,               # API 타임아웃 (초)\n",
    "    max_tokens=2000           # 최대 응답 토큰 수\n",
    ")\n",
    "\n",
    "print(\"✓ LLM 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e133d1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent 생성 완료!\n",
      "\n",
      "사용 가능한 도구: ['get_source']\n"
     ]
    }
   ],
   "source": [
    "# Agent 생성 (2025 최신 방식: create_agent 사용)\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# create_agent: 프로덕션 레벨의 agent 구현\n",
    "agent = create_agent(\n",
    "    model=llm,                    # init_chat_model로 초기화된 모델\n",
    "    tools=[get_source],           # 사용할 도구 리스트\n",
    "    system_prompt=SYSTEM_PROMPT   # System prompt (state_modifier가 아님!)\n",
    ")\n",
    "\n",
    "print(\"✓ Agent 생성 완료!\")\n",
    "print(\"\\n사용 가능한 도구:\", [tool.name for tool in [get_source]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2gy89z61ru5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.\n",
      "\n",
      "================================================================================\n",
      "저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.\n",
      "\n",
      "\n",
      "제목: Pre-training on high-resource speech recognition improves low-resource speech-to-text translation\n",
      "저자: Sameer Bansal, Herman Kamper, Karen Livescu, Adam Lopez, Sharon Goldwater\n",
      "게시일: 2018-09-05\n",
      "요약: We present a simple approach to improve direct speech-to-text translation\n",
      "(ST) when the source language is low-resource: we pre-train the model on a\n",
      "high-resource automatic speech recognition (ASR) task, and then fine-tune its\n",
      "parameters for ST. We demonstrate that our approach is effective by\n",
      "pre-training on 300 hours of English ASR data to improve Spanish-English ST\n",
      "from 10.8 to 20.2 BLEU when only 20 hours of Spanish-English ST training data\n",
      "are available. Through an ablation study, we find t...\n",
      "링크: http://arxiv.org/abs/1809.01431v2\n",
      "---\n",
      "\n",
      "\n",
      "제목: Indian Legal NLP Benchmarks : A Survey\n",
      "저자: Prathamesh Kalamkar, Janani Venugopalan Ph. D., Vivek Raghavan Ph. D\n",
      "게시일: 2021-07-13\n",
      "요약: Availability of challenging benchmarks is the key to advancement of AI in a\n",
      "specific field.Since Legal Text is significantly different than normal English\n",
      "text, there is a need to create separate Natural Language Processing benchmarks\n",
      "for Indian Legal Text which are challenging and focus on tasks specific to\n",
      "Legal Systems. This will spur innovation in applications of Natural language\n",
      "Processing for Indian Legal Text and will benefit AI community and Legal\n",
      "fraternity. We review the existing work ...\n",
      "링크: http://arxiv.org/abs/2107.06056v1\n",
      "---\n",
      "\n",
      "\n",
      "제목: IndicMMLU-Pro: Benchmarking Indic Large Language Models on Multi-Task Language Understanding\n",
      "저자: Sankalp KJ, Ashutosh Kumar, Laxmaan Balaji, Nikunj Kotecha, Vinija Jain, Aman Chadha, Sreyoshi Bhaduri\n",
      "게시일: 2025-01-27\n",
      "요약: Known by more than 1.5 billion people in the Indian subcontinent, Indic\n",
      "languages present unique challenges and opportunities for natural language\n",
      "processing (NLP) research due to their rich cultural heritage, linguistic\n",
      "diversity, and complex structures. IndicMMLU-Pro is a comprehensive benchmark\n",
      "designed to evaluate Large Language Models (LLMs) across Indic languages,\n",
      "building upon the MMLU Pro (Massive Multitask Language Understanding)\n",
      "framework. Covering major languages such as Hindi, Bengal...\n",
      "링크: http://arxiv.org/abs/2501.15747v2\n",
      "---\n",
      "\n",
      "\n",
      "제목: BELL: Benchmarking the Explainability of Large Language Models\n",
      "저자: Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala\n",
      "게시일: 2025-04-22\n",
      "요약: Large Language Models have demonstrated remarkable capabilities in natural\n",
      "language processing, yet their decision-making processes often lack\n",
      "transparency. This opaqueness raises significant concerns regarding trust,\n",
      "bias, and model performance. To address these issues, understanding and\n",
      "evaluating the interpretability of LLMs is crucial. This paper introduces a\n",
      "standardised benchmarking technique, Benchmarking the Explainability of Large\n",
      "Language Models, designed to evaluate the explainability...\n",
      "링크: http://arxiv.org/abs/2504.18572v1\n",
      "---\n",
      "\n",
      "\n",
      "제목: Consolidating and Developing Benchmarking Datasets for the Nepali Natural Language Understanding Tasks\n",
      "저자: Jinu Nyachhyon, Mridul Sharma, Prajwal Thapa, Bal Krishna Bal\n",
      "게시일: 2024-11-28\n",
      "요약: The Nepali language has distinct linguistic features, especially its complex\n",
      "script (Devanagari script), morphology, and various dialects,which pose a\n",
      "unique challenge for Natural Language Understanding (NLU) tasks. While the\n",
      "Nepali Language Understanding Evaluation (Nep-gLUE) benchmark provides a\n",
      "foundation for evaluating models, it remains limited in scope, covering four\n",
      "tasks. This restricts their utility for comprehensive assessments of Natural\n",
      "Language Processing (NLP) models. To address th...\n",
      "링크: http://arxiv.org/abs/2411.19244v2\n",
      "---\n",
      "\n",
      "다음은 저자원 언어 처리를 위한 벤치마크 구축과 관련된 최신 연구 논문들입니다. 특히 low-resource language benchmark에 관한 내용입니다.\n",
      "\n",
      "1. **Pre-training on high-resource speech recognition improves low-resource speech-to-text translation**\n",
      "   - **저자**: Sameer Bansal, Herman Kamper, Karen Livescu, Adam Lopez, Sharon Goldwater\n",
      "   - **게시일**: 2018-09-05\n",
      "   - **요약**: 이 논문은 저자원 언어에서의 직접적인 음성-텍스트 번역(ST)을 개선하기 위한 간단한 접근 방법을 제시합니다. 고자원 자동 음성 인식(ASR) 작업에서 모델을 사전 훈련한 후 ST 작업을 위해 그 매개변수를 미세 조정합니다. 300시간의 영어 ASR 데이터를 사전 훈련하여 스페인어-영어 ST를 개선한 사례를 통해 접근법의 효과를 입증합니다. [논문 링크](http://arxiv.org/abs/1809.01431v2)\n",
      "\n",
      "2. **Consolidating and Developing Benchmarking Datasets for the Nepali Natural Language Understanding Tasks**\n",
      "   - **저자**: Jinu Nyachhyon, Mridul Sharma, Prajwal Thapa, Bal Krishna Bal\n",
      "   - **게시일**: 2024-11-28\n",
      "   - **요약**: 네팔어의 복잡한 스크립트 및 다양한 방언은 자연어 이해(NLU) 작업에서 독특한 도전을 제기합니다. 기존의 Nep-gLUE 벤치마크는 네팔어 모델 평가에 기초를 제공하지만, 그 범위가 제한적입니다. 이 연구는 이러한 한계를 극복하기 위해 벤치마킹 데이터셋을 통합하고 개발하는 방법을 논의합니다. [논문 링크](http://arxiv.org/abs/2411.19244v2)\n",
      "\n",
      "이 두 논문은 저자원 언어의 자연어 처리 및 벤치마크 구축에 대한 유용한 인사이트를 제공할 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# Agent 실행 예제 쿼리\n",
    "# KLSBench 연구와 관련된 샘플 질문들\n",
    "\n",
    "# 예제 1: 저자원 언어 벤치마크 연구\n",
    "query_1 = \"저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.\"\n",
    "\n",
    "# 예제 2: 한문(Classical Chinese) 처리 연구\n",
    "query_2 = \"Classical Chinese NLP와 한문 자동 처리에 관한 연구 논문을 검색해줘.\"\n",
    "\n",
    "# 예제 3: 벤치마크 평가 방법론\n",
    "query_3 = \"NLP 벤치마크의 평가 방법론과 데이터셋 구축 방법에 대한 논문을 찾아줘.\"\n",
    "\n",
    "# Agent 실행 (원하는 쿼리 주석 해제하여 실행)\n",
    "user_query = query_1  # 여기서 query_1, query_2, query_3 중 선택\n",
    "\n",
    "print(f\"질문: {user_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Agent 스트리밍 실행\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [(\"user\", user_query)]},\n",
    "    stream_mode=\"values\"\n",
    "):\n",
    "    # 마지막 메시지만 출력\n",
    "    if \"messages\" in chunk and chunk[\"messages\"]:\n",
    "        last_message = chunk[\"messages\"][-1]\n",
    "        if hasattr(last_message, \"content\"):\n",
    "            print(last_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a9acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

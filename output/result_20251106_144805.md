# Research Agent Result

## Metadata

- **model**: gpt-4o
- **temperature**: 0.7
- **tools**: get_source

## Query

저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.

---

## Results

### Step 1: HumanMessage

저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.

### Step 2: AIMessage



### Step 3: ToolMessage



제목: Ling-CL: Understanding NLP Models through Linguistic Curricula

저자: Mohamed Elgaar, Hadi Amiri

게시일: 2023-10-31

요약: We employ a characterization of linguistic complexity from psycholinguistic

and language acquisition research to develop data-driven curricula to

understand the underlying linguistic knowledge that models learn to address NLP

tasks. The novelty of our approach is in the development of linguistic

curricula derived from data, existing knowledge about linguistic complexity,

and model behavior during training. By analyzing several benchmark NLP

datasets, our curriculum learning approaches identify s...

링크: http://arxiv.org/abs/2310.20121v1

---





제목: A Systematic Survey of Natural Language Processing for the Greek Language

저자: Juli Bakagianni, Kanella Pouli, Maria Gavriilidou, John Pavlopoulos

게시일: 2024-07-13

요약: Comprehensive monolingual Natural Language Processing (NLP) surveys are

essential for assessing language-specific challenges, resource availability,

and research gaps. However, existing surveys often lack standardized

methodologies, leading to selection bias and fragmented coverage of NLP tasks

and resources. This study introduces a generalizable framework for systematic

monolingual NLP surveys. Our approach integrates a structured search protocol

to minimize bias, an NLP task taxonomy for class...

링크: http://arxiv.org/abs/2407.09861v4

---





제목: MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling

저자: Yu Song, Santiago Miret, Bang Liu

게시일: 2023-05-14

요약: We present MatSci-NLP, a natural language benchmark for evaluating the

performance of natural language processing (NLP) models on materials science

text. We construct the benchmark from publicly available materials science text

data to encompass seven different NLP tasks, including conventional NLP tasks

like named entity recognition and relation classification, as well as NLP tasks

specific to materials science, such as synthesis action retrieval which relates

to creating synthesis procedures f...

링크: http://arxiv.org/abs/2305.08264v1

---





제목: WYWEB: A NLP Evaluation Benchmark For Classical Chinese

저자: Bo Zhou, Qianglong Chen, Tianyu Wang, Xiaomi Zhong, Yin Zhang

게시일: 2023-05-23

요약: To fully evaluate the overall performance of different NLP models in a given

domain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and

CLUE. The fi eld of natural language understanding has traditionally focused on

benchmarks for various tasks in languages such as Chinese, English, and

multilingua, however, there has been a lack of attention given to the area of

classical Chinese, also known as "wen yan wen", which has a rich history

spanning thousands of years and holds signi...

링크: http://arxiv.org/abs/2305.14150v1

---





제목: BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark

저자: Dakuan Lu, Hengkui Wu, Jiaqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin, Yanghua Xiao

게시일: 2023-02-18

요약: To advance Chinese financial natural language processing (NLP), we introduce

BBT-FinT5, a new Chinese financial pre-training language model based on the T5

model. To support this effort, we have built BBT-FinCorpus, a large-scale

financial corpus with approximately 300GB of raw text from four different

sources. In general domain NLP, comprehensive benchmarks like GLUE and

SuperGLUE have driven significant advancements in language model pre-training

by enabling head-to-head comparisons among mode...

링크: http://arxiv.org/abs/2302.09432v2

---



### Step 4: AIMessage

다음은 저자원 언어 처리를 위한 벤치마크 구축과 관련된 최신 논문들입니다. 각 논문은 저자원 언어 처리의 다양한 측면을 다루고 있습니다.



1. **Ling-CL: Understanding NLP Models through Linguistic Curricula**

   - **저자:** Mohamed Elgaar, Hadi Amiri

   - **요약:** 이 논문은 심리언어학 및 언어 습득 연구에서의 언어 복잡성 특성을 활용하여 NLP 모델이 학습하는 언어적 지식을 이해하기 위한 데이터 기반 커리큘럼을 개발합니다. 데이터로부터 파생된 언어 커리큘럼을 통해 모델의 행동을 분석하고 여러 NLP 벤치마크 데이터셋을 통해 해당 커리큘럼 학습 접근 방식을 연구합니다.

   - [링크](http://arxiv.org/abs/2310.20121v1)



2. **A Systematic Survey of Natural Language Processing for the Greek Language**

   - **저자:** Juli Bakagianni, Kanella Pouli, Maria Gavriilidou, John Pavlopoulos

   - **요약:** 이 연구는 특정 언어에 대한 NLP 과제와 자원 가용성을 평가하기 위한 체계적인 방법론을 제안합니다. 기존의 서베이가 표준화된 방법론이 부족하다는 문제를 해결하기 위해 구조화된 검색 프로토콜과 NLP 과제 분류 체계를 통합합니다.

   - [링크](http://arxiv.org/abs/2407.09861v4)



3. **MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling**

   - **저자:** Yu Song, Santiago Miret, Bang Liu

   - **요약:** 이 논문은 재료 과학 텍스트의 자연어 처리(NLP) 모델 평가를 위한 벤치마크를 제안합니다. 공개적으로 사용 가능한 재료 과학 텍스트 데이터를 활용하여 명명 엔티티 인식, 관계 분류 등 7가지 NLP 과제를 포함합니다.

   - [링크](http://arxiv.org/abs/2305.08264v1)



4. **WYWEB: A NLP Evaluation Benchmark For Classical Chinese**

   - **저자:** Bo Zhou, Qianglong Chen, Tianyu Wang, Xiaomi Zhong, Yin Zhang

   - **요약:** 이 논문은 고전 중국어에 대한 NLP 평가 벤치마크를 제안하여 전통적으로 주목받지 못했던 고전 중국어의 자연어 이해 성능을 평가합니다.

   - [링크](http://arxiv.org/abs/2305.14150v1)



5. **BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark**

   - **저자:** Dakuan Lu, Hengkui Wu, Jiaqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin, Yanghua Xiao

   - **요약:** 중국 금융 도메인 NLP의 발전을 위해 T5 모델 기반의 새로운 금융 사전 학습 언어 모델을 소개하며, 300GB 규모의 금융 코퍼스를 구축하여 모델의 성능을 비교합니다.

   - [링크](http://arxiv.org/abs/2302.09432v2)



이 논문들은 저자원 언어 처리 및 벤치마크 구축에 대한 다양한 접근 방식을 제시하며, 특히 각 언어와 도메인에 특화된 연구를 포함합니다.

---

Generated at: 2025-11-06 14:48:05

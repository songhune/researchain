% Generated from query: 저자원 언어 처리를 위한 벤치마크 구축에 대한 최신 연구를 찾아줘. 특히 low-resource language benchmark 관련 논문이 필요해.
% Generated at: 2025-11-06 14:48:05
% Total papers: 5

@article{-1,
  title = {Ling-CL: Understanding NLP Models through Linguistic Curricula},
  author = {Mohamed Elgaar, Hadi Amiri},
  year = {2023},
  abstract = {We employ a characterization of linguistic complexity from psycholinguistic
and language acquisition research to develop data-driven curricula to
understand the underlying linguistic knowledge that models learn to address NLP
tasks. The novelty of our approach is in the development of linguistic
curricula derived from data, existing knowledge about linguistic complexity,
and model behavior during training. By analyzing several benchmark NLP
datasets, our curriculum learning approaches identify s},
  eprint = {2310.20121v1},
  archivePrefix = {arXiv},
  url = {http://arxiv.org/abs/2310.20121v1},
  note = {Published: 2023-10-31}
}

@article{-2,
  title = {A Systematic Survey of Natural Language Processing for the Greek Language},
  author = {Juli Bakagianni, Kanella Pouli, Maria Gavriilidou, John Pavlopoulos},
  year = {2024},
  abstract = {Comprehensive monolingual Natural Language Processing (NLP) surveys are
essential for assessing language-specific challenges, resource availability,
and research gaps. However, existing surveys often lack standardized
methodologies, leading to selection bias and fragmented coverage of NLP tasks
and resources. This study introduces a generalizable framework for systematic
monolingual NLP surveys. Our approach integrates a structured search protocol
to minimize bias, an NLP task taxonomy for class},
  eprint = {2407.09861v4},
  archivePrefix = {arXiv},
  url = {http://arxiv.org/abs/2407.09861v4},
  note = {Published: 2024-07-13}
}

@article{-3,
  title = {MatSci-NLP: Evaluating Scientific Language Models on Materials Science Language Tasks Using Text-to-Schema Modeling},
  author = {Yu Song, Santiago Miret, Bang Liu},
  year = {2023},
  abstract = {We present MatSci-NLP, a natural language benchmark for evaluating the
performance of natural language processing (NLP) models on materials science
text. We construct the benchmark from publicly available materials science text
data to encompass seven different NLP tasks, including conventional NLP tasks
like named entity recognition and relation classification, as well as NLP tasks
specific to materials science, such as synthesis action retrieval which relates
to creating synthesis procedures f},
  eprint = {2305.08264v1},
  archivePrefix = {arXiv},
  url = {http://arxiv.org/abs/2305.08264v1},
  note = {Published: 2023-05-14}
}

@article{-4,
  title = {WYWEB: A NLP Evaluation Benchmark For Classical Chinese},
  author = {Bo Zhou, Qianglong Chen, Tianyu Wang, Xiaomi Zhong, Yin Zhang},
  year = {2023},
  abstract = {To fully evaluate the overall performance of different NLP models in a given
domain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and
CLUE. The fi eld of natural language understanding has traditionally focused on
benchmarks for various tasks in languages such as Chinese, English, and
multilingua, however, there has been a lack of attention given to the area of
classical Chinese, also known as "wen yan wen", which has a rich history
spanning thousands of years and holds signi},
  eprint = {2305.14150v1},
  archivePrefix = {arXiv},
  url = {http://arxiv.org/abs/2305.14150v1},
  note = {Published: 2023-05-23}
}

@article{-5,
  title = {BBT-Fin: Comprehensive Construction of Chinese Financial Domain Pre-trained Language Model, Corpus and Benchmark},
  author = {Dakuan Lu, Hengkui Wu, Jiaqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin, Yanghua Xiao},
  year = {2023},
  abstract = {To advance Chinese financial natural language processing (NLP), we introduce
BBT-FinT5, a new Chinese financial pre-training language model based on the T5
model. To support this effort, we have built BBT-FinCorpus, a large-scale
financial corpus with approximately 300GB of raw text from four different
sources. In general domain NLP, comprehensive benchmarks like GLUE and
SuperGLUE have driven significant advancements in language model pre-training
by enabling head-to-head comparisons among mode},
  eprint = {2302.09432v2},
  archivePrefix = {arXiv},
  url = {http://arxiv.org/abs/2302.09432v2},
  note = {Published: 2023-02-18}
}

